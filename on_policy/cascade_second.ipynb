{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from scipy.special import expit as sigmoid\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import time\n",
    "from itertools import count\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from a2c_ppo_acktr import utils\n",
    "\n",
    "from layer import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args(object):\n",
    "    num_hidden = 8\n",
    "    bandwidth = 3\n",
    "    eval_interval = None\n",
    "    log_interval = 250\n",
    "    use_gae = False\n",
    "    num_updates = 1e5\n",
    "    num_steps = 32\n",
    "    memory_capacity = num_steps\n",
    "    ppo_epoch = 1\n",
    "    num_mini_batch = 32\n",
    "    value_loss_coef = 0.5\n",
    "    entropy_coef = 0.01\n",
    "    lr = 1e-3\n",
    "    eps = 1e-5\n",
    "    max_grad_norm = 0.2\n",
    "    clip_param = 0.2\n",
    "    gamma = 0.99\n",
    "    gae_lambda = 0.95\n",
    "    use_proper_time_limits = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f1ery/.local/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "input = Layer(4, 1, args.bandwidth, post_width=args.num_hidden, args=args, post_process=None)\n",
    "hidden = Layer(args.num_hidden, args.bandwidth, args.bandwidth, post_width=1, args=args, post_process=None)\n",
    "output = Layer(1, args.bandwidth, 1, post_process=sigmoid, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f1ery/.local/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 250, Avg/Max/Min. reward: 20.7/63.0/8.0\n",
      "Iter: 500, Avg/Max/Min. reward: 24.2/123.0/9.0\n",
      "Iter: 750, Avg/Max/Min. reward: 24.9/84.0/8.0\n",
      "Iter: 1000, Avg/Max/Min. reward: 23.6/86.0/9.0\n",
      "Iter: 1250, Avg/Max/Min. reward: 26.1/93.0/9.0\n",
      "Iter: 1500, Avg/Max/Min. reward: 24.4/114.0/9.0\n",
      "Iter: 1750, Avg/Max/Min. reward: 22.2/81.0/9.0\n",
      "Iter: 2000, Avg/Max/Min. reward: 22.4/85.0/9.0\n",
      "Iter: 2250, Avg/Max/Min. reward: 22.0/71.0/9.0\n",
      "Iter: 2500, Avg/Max/Min. reward: 22.5/71.0/9.0\n",
      "Iter: 2750, Avg/Max/Min. reward: 22.2/78.0/9.0\n",
      "Iter: 3000, Avg/Max/Min. reward: 22.5/84.0/8.0\n",
      "Iter: 3250, Avg/Max/Min. reward: 22.6/83.0/8.0\n",
      "Iter: 3500, Avg/Max/Min. reward: 22.6/68.0/8.0\n",
      "Iter: 3750, Avg/Max/Min. reward: 22.1/68.0/8.0\n",
      "Iter: 4000, Avg/Max/Min. reward: 21.6/62.0/9.0\n",
      "Iter: 4250, Avg/Max/Min. reward: 22.3/67.0/9.0\n",
      "Iter: 4500, Avg/Max/Min. reward: 22.4/71.0/9.0\n",
      "Iter: 4750, Avg/Max/Min. reward: 23.5/77.0/9.0\n",
      "Iter: 5000, Avg/Max/Min. reward: 22.4/69.0/9.0\n",
      "Iter: 5250, Avg/Max/Min. reward: 21.9/69.0/9.0\n",
      "Iter: 5500, Avg/Max/Min. reward: 22.4/86.0/8.0\n",
      "Iter: 5750, Avg/Max/Min. reward: 21.7/90.0/8.0\n",
      "Iter: 6000, Avg/Max/Min. reward: 22.2/96.0/9.0\n",
      "Iter: 6250, Avg/Max/Min. reward: 21.7/83.0/9.0\n",
      "Iter: 6500, Avg/Max/Min. reward: 21.7/90.0/9.0\n",
      "Iter: 6750, Avg/Max/Min. reward: 23.1/86.0/9.0\n",
      "Iter: 7000, Avg/Max/Min. reward: 23.4/160.0/8.0\n",
      "Iter: 7250, Avg/Max/Min. reward: 22.3/160.0/8.0\n",
      "Iter: 7500, Avg/Max/Min. reward: 23.6/74.0/8.0\n",
      "Iter: 7750, Avg/Max/Min. reward: 23.5/90.0/8.0\n",
      "Iter: 8000, Avg/Max/Min. reward: 23.1/116.0/8.0\n",
      "Iter: 8250, Avg/Max/Min. reward: 21.5/116.0/8.0\n",
      "Iter: 8500, Avg/Max/Min. reward: 21.4/85.0/8.0\n",
      "Iter: 8750, Avg/Max/Min. reward: 21.3/69.0/8.0\n",
      "Iter: 9000, Avg/Max/Min. reward: 22.1/88.0/8.0\n",
      "Iter: 9250, Avg/Max/Min. reward: 22.0/79.0/8.0\n",
      "Iter: 9500, Avg/Max/Min. reward: 22.7/83.0/8.0\n",
      "Iter: 9750, Avg/Max/Min. reward: 22.4/78.0/9.0\n",
      "Iter: 10000, Avg/Max/Min. reward: 24.8/102.0/8.0\n",
      "Iter: 10250, Avg/Max/Min. reward: 22.8/102.0/8.0\n",
      "Iter: 10500, Avg/Max/Min. reward: 22.2/106.0/9.0\n",
      "Iter: 10750, Avg/Max/Min. reward: 21.9/81.0/9.0\n",
      "Iter: 11000, Avg/Max/Min. reward: 22.5/119.0/9.0\n",
      "Iter: 11250, Avg/Max/Min. reward: 21.6/88.0/8.0\n",
      "Iter: 11500, Avg/Max/Min. reward: 21.4/70.0/8.0\n",
      "Iter: 11750, Avg/Max/Min. reward: 22.3/75.0/8.0\n",
      "Iter: 12000, Avg/Max/Min. reward: 22.1/67.0/9.0\n",
      "Iter: 12250, Avg/Max/Min. reward: 22.7/77.0/9.0\n",
      "Iter: 12500, Avg/Max/Min. reward: 22.6/81.0/8.0\n",
      "Iter: 12750, Avg/Max/Min. reward: 22.5/72.0/9.0\n",
      "Iter: 13000, Avg/Max/Min. reward: 23.1/91.0/10.0\n",
      "Iter: 13250, Avg/Max/Min. reward: 22.6/76.0/9.0\n",
      "Iter: 13500, Avg/Max/Min. reward: 23.0/65.0/8.0\n",
      "Iter: 13750, Avg/Max/Min. reward: 22.2/96.0/8.0\n",
      "Iter: 14000, Avg/Max/Min. reward: 22.4/66.0/9.0\n",
      "Iter: 14250, Avg/Max/Min. reward: 22.9/92.0/8.0\n",
      "Iter: 14500, Avg/Max/Min. reward: 22.4/85.0/8.0\n",
      "Iter: 14750, Avg/Max/Min. reward: 23.3/85.0/8.0\n",
      "Iter: 15000, Avg/Max/Min. reward: 21.0/71.0/8.0\n",
      "Iter: 15250, Avg/Max/Min. reward: 21.3/86.0/8.0\n",
      "Iter: 15500, Avg/Max/Min. reward: 22.9/101.0/8.0\n",
      "Iter: 15750, Avg/Max/Min. reward: 22.7/74.0/8.0\n",
      "Iter: 16000, Avg/Max/Min. reward: 21.8/74.0/8.0\n",
      "Iter: 16250, Avg/Max/Min. reward: 22.9/79.0/8.0\n",
      "Iter: 16500, Avg/Max/Min. reward: 23.8/74.0/8.0\n",
      "Iter: 16750, Avg/Max/Min. reward: 22.3/65.0/9.0\n",
      "Iter: 17000, Avg/Max/Min. reward: 22.7/82.0/8.0\n",
      "Iter: 17250, Avg/Max/Min. reward: 22.3/61.0/9.0\n",
      "Iter: 17500, Avg/Max/Min. reward: 21.1/68.0/9.0\n",
      "Iter: 17750, Avg/Max/Min. reward: 21.6/91.0/8.0\n",
      "Iter: 18000, Avg/Max/Min. reward: 22.4/94.0/8.0\n",
      "Iter: 18250, Avg/Max/Min. reward: 21.4/74.0/8.0\n",
      "Iter: 18500, Avg/Max/Min. reward: 22.3/95.0/9.0\n",
      "Iter: 18750, Avg/Max/Min. reward: 24.3/95.0/9.0\n",
      "Iter: 19000, Avg/Max/Min. reward: 23.5/74.0/9.0\n",
      "Iter: 19250, Avg/Max/Min. reward: 23.7/114.0/9.0\n",
      "Iter: 19500, Avg/Max/Min. reward: 24.2/121.0/8.0\n",
      "Iter: 19750, Avg/Max/Min. reward: 22.6/75.0/8.0\n",
      "Iter: 20000, Avg/Max/Min. reward: 23.4/91.0/8.0\n",
      "Iter: 20250, Avg/Max/Min. reward: 23.2/97.0/8.0\n",
      "Iter: 20500, Avg/Max/Min. reward: 22.7/80.0/8.0\n",
      "Iter: 20750, Avg/Max/Min. reward: 22.9/87.0/9.0\n",
      "Iter: 21000, Avg/Max/Min. reward: 22.7/126.0/8.0\n",
      "Iter: 21250, Avg/Max/Min. reward: 21.5/76.0/9.0\n",
      "Iter: 21500, Avg/Max/Min. reward: 23.3/76.0/9.0\n",
      "Iter: 21750, Avg/Max/Min. reward: 22.4/79.0/8.0\n",
      "Iter: 22000, Avg/Max/Min. reward: 21.0/77.0/8.0\n",
      "Iter: 22250, Avg/Max/Min. reward: 22.6/91.0/8.0\n",
      "Iter: 22500, Avg/Max/Min. reward: 22.8/81.0/8.0\n",
      "Iter: 22750, Avg/Max/Min. reward: 21.8/71.0/8.0\n",
      "Iter: 23000, Avg/Max/Min. reward: 21.6/76.0/8.0\n",
      "Iter: 23250, Avg/Max/Min. reward: 22.9/69.0/9.0\n",
      "Iter: 23500, Avg/Max/Min. reward: 21.9/85.0/8.0\n",
      "Iter: 23750, Avg/Max/Min. reward: 22.9/85.0/8.0\n",
      "Iter: 24000, Avg/Max/Min. reward: 22.3/81.0/8.0\n",
      "Iter: 24250, Avg/Max/Min. reward: 23.3/82.0/9.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-abccd3a21502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cascade_rl/on_policy/layer.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0munit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cascade_rl/on_policy/unit.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m                                self.args.gae_lambda, self.args.use_proper_time_limits)\n\u001b[1;32m     69\u001b[0m         \u001b[0mvalue_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_entropies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cascade_rl/on_policy/a2c_ppo_acktr/algo/ppo.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, rollouts)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mvalue_loss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0maction_loss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maction_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episode_rewards = deque(maxlen=args.log_interval)\n",
    "done = True\n",
    "\n",
    "for j in count(len(input.units[0].action_losses) + 1):\n",
    "    input.clear_memory()\n",
    "    hidden.clear_memory()\n",
    "    output.clear_memory()\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        episode_rewards.append(0)\n",
    "        input.reset()\n",
    "        hidden.reset()\n",
    "        output.reset()\n",
    "    for unit in input.units + hidden.units + output.units:\n",
    "        utils.update_linear_schedule(unit.agent.optimizer, j, args.num_updates, args.lr)\n",
    "    for step in range(args.num_steps):\n",
    "        action = output(hidden(input([state[i:i+1] for i in range(4)])))[0][0]\n",
    "        action = int(action > 0.5)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        input.reward(reward)\n",
    "        hidden.reward(reward)\n",
    "        output.reward(reward)\n",
    "        episode_rewards[-1] += reward\n",
    "        if done:\n",
    "            input.done()\n",
    "            hidden.done()\n",
    "            output.done()\n",
    "    input.update()\n",
    "    hidden.update()\n",
    "    output.update()\n",
    "    if j % args.log_interval == 0:\n",
    "        print('Iter: %d, Avg/Max/Min. reward: %0.1f/%0.1f/%0.1f' % (j, sum(episode_rewards)/len(episode_rewards), max(episode_rewards), min(episode_rewards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('INPUTS')\n",
    "input.plot_stats(n=10000)\n",
    "print('HIDDEN')\n",
    "hidden.plot_stats(n=10000)\n",
    "print('OUTPUTS')\n",
    "output.plot_stats(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
